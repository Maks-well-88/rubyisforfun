## Testing Ruby programs

What is software testing? The definition is quite broad, therefore there is plenty of testing methodologies exist.

Imagine a hardware engineer just built the radio from a set of components, and wants to understand if it works or not. She'll probably use so called smoke testing, when you turn on and off the power supply quickly to see if there isn't any smoke, to find out there is no fundamental failures. If there is no any smoke, one can proceed to "happy path" testing, turning on the radio, and trying to tune it in to some radio station to check if there is any sound.

There can be other tests before the radio goes for production. For example, load testing to measure the electricity consumption. The radio probably should be power-efficient, so people won't need to change batteries every day. Even if the radio works, and there is a sound, battery drain problem can be a marketing failure, and the product won't succeed.

Some tests can involve assembly testing, so it works as expected over extended period of time when it is installed inside of a truck or any other vehicle. The number and depth of these tests depend on requirements. Are we just building pocket radio or military-grade radio? Answers to this fundamental questions define the product quality, and define the testing methodologies we're going to use.

The same is true in software testing. There are numerous of testing methodologies, like manual testing, automated testing, unit testing, integration, load, and so on. It takes a lot of time to get familiar with all of these concepts, each methodology is probably represented by hundreds of books. We'll take a look into the most popular tests software developers face on their day-to-day basis: unit tests. What are unit tests and why there is a need for them?

About 30 years ago almost nobody was looking at software testing like at something important. Programs were made in text editors, and folks used to just run them (or send to their clients on floppy disks, CD-ROMs and later through Internet). In case of an error or incorrect behavior programmers used to fix the software and ship the new release. Normally, these releases included a set of bug fixes. 

However, complexity of software products was increasing. The number of developers in a teams was increasing. Often a small change could introduce a bug. For sure, some number of these bugs used to get caught by manual testing (or testers). However, it was not enough.

The question of identifying bugs on early stages has emerged. If there is a software module, or critical unit, is it possible to make it fool-proof, so it will be harder to break? It's like in real life, morning routine says to double check the iron and stove are off before you go to work. You are almost certain that these are off, but the price to verify that is almost nothing compared to the damage it can cause in case something is not right. 

The same is true for programming:

* Instead of checking the iron or gas stove, we double check software units of the same program.
* Instead of checking it only once, programmers run automated checks after every change.

Will you agree that it's much easier? Software developers change their programs, run tests, and make sure that everything works as expected. If something breaks, one can fix it right away, without shipping a software to end users and releasing broken version to production. So identifying bugs is a matter of seconds or minutes (for example, running 500 automated tests normally takes a couple of minutes), not days.

For a relatively simple project, for every 100 changes we'll run 500 tests for each, which gives about 50 thousand test runs. As you can imagine, it's much harder to introduce bugs having tests culture on a project in place, and software quality improves dramatically. However, unit-testing is not free.

Engineers need to write these tests. While writing tests isn't hard, it requires time, and businesses need to invest time and money into tests. Good tests require the knowledge of testing frameworks, testing methodologies, and some experience writing these tests.

At the same time it's not possible to cover absolutely everything with tests. Ten `if...else` statements in your program are 2 (number of possible branches for each statement) in the power of 10 (number of statements) code flow combinations, 1024 total for such a small number of conditions.

Some programs use "code coverage" term, represented in percentage. You can hear something like "the code coverage for our project is 80%", which is often something to be proud about. The question though is how this number was calculated. Yes, some modules can be covered with tests pretty extensively. But even with 100% coverage, the number of possible ways of how a real-life program can be executed is much more than the number of tests (assuming the program has at least a thousand lines of code).

Also, developers often create tests as soon as they write some code. But on initial stages, the software design often isn't fixed. Programmers do experiment as artists do multiple sketches before in putting the final details to a landscape drawing. Making design final at the first attempt is close to impossible. And good amount of unit tests fix application design at the stage when it is still fresh.

With removing unnecessary code one needs to remove related tests. From a business perspective you are doubling your expenses while getting rid of something you've spent money on.

With all these cons, unit testing is no question practice that greatly improved software quality. Businesses understand the value, and heavily invest in building reliable software solutions. Unit testing is a standard, and there is no any software frameworks that don't come with built-in test tools today. In the next chapter we'll take a closer look into popular testing framework for Ruby called "Rspec".